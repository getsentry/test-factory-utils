{% set labels = {
  "service": "telegraf",
  "component": "proxy",
} %}
# An Nginx-based proxy that balances UDP traffic between the pool of Telegraf
# workers.
# Why do we need it? Why not just a K8S service?
# The case we optimize for here is when a single UDP client sends A LOT of StatsD traffic, that
# cannot be handled by a single Telegraf instance. Since it's a single client (single socket), the K8S
# service directs all traffic to one backend pod, without proper load balancing.
---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: telegraf-proxy
  namespace: sentry-system
  labels: {{ labels }}
spec:
  replicas: 1
  selector:
    matchLabels: {{ labels }}
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  template:
    metadata:
      labels: {{ labels }}
    spec:
      initContainers:
      - image: busybox:1.32
        name: write-nginx-config
        command:
        - sh
        - -c
        - |
          echo '
          # Nginx config
          user nginx;
          worker_processes auto;

          error_log /var/log/nginx/error.log notice;
          pid /var/run/nginx.pid;

          events {
            worker_connections  2048;
          }

          stream {
            server {
              listen 8125 udp;
              proxy_pass telegraf-workers.sentry-system.svc.cluster.local:8125;
              proxy_responses 0;
            }
          }

          http {}
          ' > /etc/nginx/nginx.conf
        volumeMounts:
          - name: nginx-config
            mountPath: /etc/nginx
      containers:
      - image: nginx:1.20
        name: telegraf-proxy-nginx
        volumeMounts:
          - name: nginx-config
            mountPath: /etc/nginx
        resources:
          requests:
            cpu: 1000m
            memory: 400Mi
          limits:
            cpu: 10000m
            memory: 800Mi
      volumes:
      - name: nginx-config
        emptyDir: {}
