apiVersion: argoproj.io/v1alpha1
kind: WorkflowTemplate
metadata:
  name: z-snuba
  namespace: argo
spec:
  podGC:
    strategy: OnWorkflowCompletion
  templates:

  # Stop all Snuba services
  - name: snuba-stop-all
    container:
      name: kubectl
      image: bitnami/kubectl:1.19
      command:
      - kubectl
      - scale
      - deployment
      - --namespace=default
      - --replicas=0
      - --selector=service=snuba
      - --timeout=60s
    serviceAccountName: default

  # Wait for rollout
  - name: snuba-wait-for-rollout
    container:
      command:
      - kubectl
      - rollout
      - status
      - deployment
      - --namespace=default
      - snuba-metrics-consumer
      - --timeout=60s
      image: bitnami/kubectl:1.19
      name: kubectl
    serviceAccountName: default

  - name: run-snuba-migrations
    inputs:
      parameters:
      - name: snuba_sha
        value: default
    container:
      image: bitnami/kubectl:1.19
      command:
        - bash
        - -c
        - |
          exec 2>&1
          set -euo pipefail

          SNUBA_SHA='{% raw %}{{inputs.parameters.snuba_sha}}{% endraw %}'
          if [[ "${SNUBA_SHA}" == "default" ]]; then
            SNUBA_IMAGE=$(kubectl get deployment -n default snuba-metrics-consumer -o jsonpath='{.spec.template.spec.containers[0].image}')
          else
            SNUBA_IMAGE="us.gcr.io/sentryio/snuba:${SNUBA_SHA}"
          fi

          if [[ "${SNUBA_IMAGE}" != *"sentryio/snuba"* ]]; then
            echo "Incorrect Snuba image: ${SNUBA_IMAGE}"
            exit 1
          fi
          echo "Using Snuba image: ${SNUBA_IMAGE}"

          POD_NAME="run-snuba-migrations-{% raw %}{{workflow.uid}}{% endraw %}"

          # FIXME: extract this to a job?
          # FIXME: why is it not just a container step?
          # 2 reasons:
          #   * We first need to figure out what image to run
          #   * It seems to be impossible to start a pod in a different namespace (not "argo") from a step
          cat <<EOF >/tmp/pod.yaml
          apiVersion: v1
          kind: Pod
          metadata:
            name: "${POD_NAME}"
            namespace: "default"
            labels:
              workflowTemplate: 'run-snuba-migrations'
          spec:
            containers:
              - image: "${SNUBA_IMAGE}"
                name: snuba-metrics-consumer-migrate
                args:
                - bootstrap
                - '--force'
                resources:
                  requests:
                    cpu: 500m
                    memory: 1000Mi
                  limits:
                    cpu: 2000m
                    memory: 1000Mi
                # Note: these mounts and env vars have to be the same as for other Snuba containers
                volumeMounts:
                  - name: snuba-config
                    mountPath: /etc/snuba/settings.py
                    subPath: settings.py
                    readOnly: true
                env:
                  - name: SNUBA_SETTINGS
                    value: /etc/snuba/settings.py
            volumes:
              - name: snuba-config
                configMap:
                  name: snuba
            restartPolicy: Never
          EOF
          kubectl apply -f /tmp/pod.yaml

          echo 'Waiting for the migration to finish...'
          RET=0
          while true; do
            PHASE=$(kubectl get pod -n default "${POD_NAME}" -o jsonpath='{.status.phase}')
            if [[ "${PHASE}" == "Succeeded" ]]; then
              echo 'Done!'
              RET=0
              break
            elif [[ "${PHASE}" == "Failed" ]]; then
              echo 'Error!'
              kubectl desribe pod -n default "${POD_NAME}"
              RET=1
              break
            elif [[ ${PHASE} == "" ]]; then
              echo 'Something went wrong.'
              RET=1
              break
            else
              echo "[$(date)] Waiting..."
              sleep 5
            fi
          done
          kubectl logs -n default "${POD_NAME}"
          exit "${RET}"
    serviceAccountName: default
  ttlStrategy:
    # 3 days
    secondsAfterCompletion: 259200

  - name: snuba-update-configuration
    inputs:
      parameters:
      - name: wait_for_rollout
        value: '1'
      artifacts:
      - name: test-factory-src
        path: /root/test-factory
    container:
      name: sentry-kube
      # getsentry/ops branch: feat/sentry-kube-no-context
      image: "europe-west3-docker.pkg.dev/sentry-st-testing/main/sentry-kube:f575c8bb772339b61bc0caa8a337dec24ddc2642"
      command:
      - bash
      - '-c'
      - |
        exec 2>&1
        set -euxo pipefail

        # Needed for sentry-kube
        git init

        # Update snuba version
        yq eval -i '.image_tag = "{% raw %}{{workflow.outputs.parameters.snuba_sha}}{% endraw %}"' ./k8s/services/snuba/_values.yaml

        # FIXME: sentry-kube should be updated to handle this
        # sentry-kube diff-beta snuba
        sentry-kube render snuba > _snuba.yaml

        # Add an annotation with run ID
        yq eval '(select(.kind == "Deployment") | .spec.template.metadata.annotations.argoWorkflowId) = "{% raw %}{{workflow.uid}}{% endraw %}"' _snuba.yaml > _snuba.processed.yaml

        # FIXME: do not hardcode namespaces
        sentry-kube kubectl apply -n default -f _snuba.processed.yaml

        ### Wait for rollout, if told
        WAIT_FOR_ROLLOUT=$(echo "{% raw %}{{inputs.parameters.wait_for_rollout}}{% endraw %}" | tr '[:upper:]' '[:lower:]')
        TRUTHY_VALUES=("1" "yes" "true")

        if [[ " ${TRUTHY_VALUES[*]} " == *" ${WAIT_FOR_ROLLOUT} "* ]]; then
          echo "Waiting for the rollout to finish..."
          sentry-kube kubectl rollout status deployment -n default snuba-metrics-consumer --timeout=60s
        fi

    serviceAccountName: default
